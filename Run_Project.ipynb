{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import create_aws as aws\n",
    "import create_tables\n",
    "import etl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 1. Creating Redshift Cluster using the AWS python SDK\n",
    "\n",
    "## 1.1 Creating IAM Role and Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: IAM ROLE\n",
      "1.1 Creating a new IAM Role\n",
      "1.2 Attaching Policy\n",
      "1.3 Get the IAM role ARN\n",
      "arn:aws:iam::128300692899:role/sparkifyRole\n",
      "2.0 Creating Cluster\n",
      "X.X End Creating: Wait the cluster status becomes \"Available\"\n"
     ]
    }
   ],
   "source": [
    "# Creating IAM Role, attaching Policy, Get the IAM role ARN and Creating Cluster.\n",
    "aws.create_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1.2 *Describe* the cluster to see its status\n",
    "- run this block several times until the cluster status becomes `Available`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ec2.SecurityGroup(id='sg-882575d9')\n",
      "An error occurred (InvalidPermission.Duplicate) when calling the AuthorizeSecurityGroupIngress operation: the specified rule \"peer: 0.0.0.0/0, TCP, from port: 5439, to port: 5439, ALLOW\" already exists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ClusterIdentifier</td>\n",
       "      <td>sparkifycluster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NodeType</td>\n",
       "      <td>dc2.large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ClusterStatus</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MasterUsername</td>\n",
       "      <td>sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DBName</td>\n",
       "      <td>db_sparkify</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Endpoint</td>\n",
       "      <td>{'Address': 'sparkifycluster.cbo25hf0jzwi.us-west-2.redshift.amazonaws.com', 'Port': 5439}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VpcId</td>\n",
       "      <td>vpc-3c83ea44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NumberOfNodes</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Key  \\\n",
       "0  ClusterIdentifier   \n",
       "1  NodeType            \n",
       "2  ClusterStatus       \n",
       "3  MasterUsername      \n",
       "4  DBName              \n",
       "5  Endpoint            \n",
       "6  VpcId               \n",
       "7  NumberOfNodes       \n",
       "\n",
       "                                                                                        Value  \n",
       "0  sparkifycluster                                                                             \n",
       "1  dc2.large                                                                                   \n",
       "2  available                                                                                   \n",
       "3  sparkify                                                                                    \n",
       "4  db_sparkify                                                                                 \n",
       "5  {'Address': 'sparkifycluster.cbo25hf0jzwi.us-west-2.redshift.amazonaws.com', 'Port': 5439}  \n",
       "6  vpc-3c83ea44                                                                                \n",
       "7  4                                                                                           "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a myClusterProps with the cluster properties.\n",
    "myClusterProps=aws.myClusterProps()\n",
    "\n",
    "# Open an incoming TCP port to access the cluster ednpoint\n",
    "aws.config_VPC(myClusterProps)\n",
    "\n",
    "# See the cluster properties.\n",
    "aws.prettyRedshiftProps(myClusterProps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# 2. Create Table Schemas and Build ETL Pipeline\n",
    "\n",
    "## 2.1 Creating Table Schemas\n",
    "- **staging_events:** event data telling what users have done (columns: *event_id, artist, auth, firstName, gender, itemInSession, lastName, length, level, location, method, page, registration, sessionId, song, status, ts, userAgent, userId*)\n",
    "\n",
    "- **staging_songs:** song data about songs and artists (columns: *num_songs, artist_id, artist_latitude, artist_longitude, artist_location, artist_name, song_id, title, duration, year*)\n",
    "\n",
    "- **songplays:** song play data together with user, artist, and song info (columns: *songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent*)\n",
    "\n",
    "- **users:** user info (columns: *user_id, first_name, last_name, gender, level*)\n",
    "\n",
    "- **songs:** song info (columns: *song_id, title, artist_id, year, duration*)\n",
    "\n",
    "- **artists:** artist info (columns: *artist_id, name, location, latitude, longitude*)\n",
    "\n",
    "- **time:** detailed time info about song plays (columns: *start_time, hour, day, week, month, year, weekday*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= DROP TABLE START =======\n",
      "======= DROP TABLE: staging_events \n",
      "======= DROP TABLE: staging_songs \n",
      "======= DROP TABLE: songplay \n",
      "======= DROP TABLE: users \n",
      "======= DROP TABLE: song \n",
      "======= DROP TABLE: artist \n",
      "======= DROP TABLE: time \n",
      "======= DROP TABLE DONE =======\n",
      "======= CREATE Table START =======\n",
      "======= CREATE TABLE: staging_events \n",
      "======= CREATE TABLE: staging_songs \n",
      "======= CREATE TABLE: songplays \n",
      "======= CREATE TABLE: users \n",
      "======= CREATE TABLE: songs \n",
      "======= CREATE TABLE: artists \n",
      "======= CREATE TABLE: time \n",
      "======= CREATE Table DONE =======\n"
     ]
    }
   ],
   "source": [
    "#DROP and Creating de tables (staging_events, staging_songs, songplay, users, song, artist, time)\n",
    "create_tables.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.2 Creating Table Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Redshift connection established OK.\n",
      "Start loading data from S3 to AWS Reshift tables...\n",
      "======= LOADING: ==> \n",
      "    COPY staging_events FROM 's3://udacity-dend/log_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::128300692899:role/sparkifyRole'\n",
      "    format as json 's3://udacity-dend/log_json_path.json'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      " =======\n",
      "=== DONE IN: 1.56 sec\n",
      "\n",
      "======= LOADING: ==> \n",
      "    COPY staging_songs FROM 's3://udacity-dend/song_data'\n",
      "    credentials 'aws_iam_role=arn:aws:iam::128300692899:role/sparkifyRole'\n",
      "    format as json 'auto'\n",
      "    ACCEPTINVCHARS AS '^'\n",
      "    STATUPDATE ON\n",
      "    region 'us-west-2';\n",
      " =======\n",
      "=== DONE IN: 84.26 sec\n",
      "\n",
      "All files COPIED OK.\n",
      "Start inserting data from staging tables into analysis tables...\n",
      "======= Insert Table ==> songplays \n",
      "=== DONE IN: 0.94 sec\n",
      "\n",
      "======= Insert Table ==> users \n",
      "=== DONE IN: 0.66 sec\n",
      "\n",
      "======= Insert Table ==> songs \n",
      "=== DONE IN: 1.10 sec\n",
      "\n",
      "======= Insert Table ==> artists \n",
      "=== DONE IN: 0.60 sec\n",
      "\n",
      "======= Insert Table ==> time \n",
      "=== DONE IN: 0.65 sec\n",
      "\n",
      "All files INSERTED OK.\n"
     ]
    }
   ],
   "source": [
    "## Loading data from S3 (staging_events and staging_songs)\n",
    "## Insert Tables (songplays, users, songs, artists and time)\n",
    "etl.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.3 Clean up your resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Clean Cluster: sparkifyCluster\n"
     ]
    }
   ],
   "source": [
    "aws.delete_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
